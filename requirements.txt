# Philosopher Engine V3 — Unified Requirements
# Install with: pip install -r requirements.txt

# ---- Z3 / SMT Verification (Layer 3) ----
z3-solver>=4.12.0
# cvc5                        # Optional: pip install cvc5 (parallel SMT)

# ---- LLM Interface ----
ollama>=0.2                    # Unified local + cloud API

# ---- ML (meta-learner) ----
# NOTE: Install PyTorch separately for your CUDA version:
#   pip install torch --index-url https://download.pytorch.org/whl/cu121
torch>=2.1.0
numpy>=1.24.0

# ---- Ontology (Layer 1, optional) ----
# owlready2>=0.46              # OWL 2 ontology

# ---- Data Processing ----
jsonlines>=4.0
pyyaml>=6.0
tqdm>=4.66.0

# ---- Corpus Assembly + Extraction (Phases 1-2) ----
requests>=2.31.0
PyMuPDF>=1.23.0                # fitz - PDF extraction

# ---- CPT Training (Phase 5 — GPU server only) ----
transformers>=4.40.0
accelerate>=0.27.0
datasets>=2.18.0
wandb>=0.16.0
bitsandbytes>=0.43.0
# flash-attn>=2.5.0           # Install separately: MAX_JOBS=4 pip install flash-attn --no-build-isolation
deepspeed>=0.14.0
sentencepiece>=0.1.99
protobuf>=4.25.0

# ---- QLoRA Option (Phase 5 alternative) ----
peft>=0.10.0
trl>=0.8.0

# ---- SFT Data Generation (Phase 6) ----
anthropic>=0.25.0              # Claude API
openai>=1.14.0                 # GPT-4 API
google-generativeai>=0.5.0     # Gemini API

# ---- Corpus Index (optional semantic search) ----
# faiss-cpu>=1.7               # Optional: FAISS for semantic search

# ---- Testing ----
pytest>=7.4
